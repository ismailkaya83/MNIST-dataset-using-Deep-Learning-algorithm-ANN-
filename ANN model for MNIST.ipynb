{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd \n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MNIST dataset\n",
    "- MNIST is a collection of handwritten digits ranging from the number 0 to 9.\n",
    "- It has a training set of 42.000 images and 28.000 test images that are classified into corresponding categories or labels."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_csv(\"train.csv\")\n",
    "test = pd.read_csv(\"test.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Target variable\n",
    "y = train.pop(\"label\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# scale the input values to type float32 and (normalize) the input values within the interval [0, 1]\n",
    "\n",
    "train = train.astype('float32')/255\n",
    "test = test.astype('float32')/255\n",
    "y = y.astype('float32')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Converting pandas Dataframe to numpy array\n",
    "\n",
    "train = pd.DataFrame.to_numpy(train)\n",
    "test = pd.DataFrame.to_numpy(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Splitting training set into train and dev set \n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "x_train, x_test, y_train, y_test = train_test_split(train, y, test_size=0.33, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((28140, 784), (13860, 784), (28140,), (13860,))"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train.shape, x_test.shape, y_train.shape, y_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "# Y variable has 10 different classes. Therefore we need to represent each values in y as vector. \n",
    "# This converst for example  1 to [0., 1., 0., 0., 0., 0., 0., 0., 0., 0.] vector. \n",
    "\n",
    "from keras.utils import to_categorical\n",
    "\n",
    "y_train = to_categorical(y_train, num_classes=10)\n",
    "\n",
    "y_test = to_categorical(y_test, num_classes=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((28140, 784), (13860, 784), (28140, 10), (13860, 10))"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train.shape, x_test.shape, y_train.shape, y_test.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model with function and KERAS"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "6.1 Sequential class in Keras \n",
    "- The main data structure in Keras is the Sequential class, which allows the creation of a basic neural network. The Sequential class of the Keras library is a wrapper for the sequential neural network model that Keras offers and can be created in the following way:\n",
    "\n",
    "- The model in Keras is considered as a sequence of layers and each of them gradually “distills” the input data to obtain the desired output. In Keras, we can add the required types of layers through the .add() method.\n",
    "\n",
    "https://www.kaggle.com/prashant111/comprehensive-guide-to-ann-with-keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers.core import Dense, Activation\n",
    "\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Dense(10, activation='sigmoid', input_shape=(784,)))\n",
    "model.add(Dense(10, activation='softmax'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### First layer\n",
    "-We explicitly express in the input_shape argument of the first layer what the input data is like: a tensor that indicates that we have 784 features of the model.\n",
    "\n",
    "-The tensor is being defined is (None, 784,).\n",
    "\n",
    "#### Second layer\n",
    "-The second layer is a softmax layer of 10 neurons, which means that it will return a matrix of 10 probability values representing the 10 possible digits.\n",
    "\n",
    "-Each value will be the probability that the image of the current digit belongs to each one of them."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Available activations\n",
    "\n",
    "- tf.keras.activations.relu(x, alpha=0.0, max_value=None, threshold=0)\n",
    "- tf.keras.activations.sigmoid(x)\n",
    "- tf.keras.activations.softmax(x, axis=-1)\n",
    "- tf.keras.activations.softplus(x)\n",
    "- tf.keras.activations.softsign(x)\n",
    "- tf.keras.activations.tanh(x)\n",
    "- tf.keras.activations.selu(x)\n",
    "- tf.keras.activations.elu(x, alpha=1.0)\n",
    "- tf.keras.activations.exponential(x)\n",
    "- tf.keras.layers.LeakyReLU(alpha=0.3, **kwargs)\n",
    "- tf.keras.layers.PReLU(alpha_initializer=\"zeros\",alpha_regularizer=None,alpha_constraint=None,shared_axes=None,**kwargs)\n",
    "- tf.keras.layers.ThresholdedReLU(theta=1.0, **kwargs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_1 (Dense)              (None, 10)                7850      \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 10)                110       \n",
      "=================================================================\n",
      "Total params: 7,960\n",
      "Trainable params: 7,960\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary() # Keras provides a very useful method to check the architecture of the model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- For our simple example, we see that it indicates that 7,960 parameters are required (column Param #), which correspond to 7850 parameters to the first layer and 110 to the second.\n",
    "- In the first layer, for each neuron i (between 0 and 9) we require 784 parameters for the weights wij and therefore 10×784=7840 parameters to store the weights of the 10 neurons.\n",
    "- Also, 10 additional parameters for the 10 bj biases corresponding to each one of them is required.\n",
    "- So, for the first layer we require 7840 + 10 = 7850 parameters.\n",
    "\n",
    "- In the second layer, being a softmax function, it is required to connect all 10 neurons with the 10 neurons of the previous layer.\n",
    "- Therefore 10x10=100 wi parameters are required and in addition 10 bj biases corresponding to each node is required.\n",
    "- So, we require 100 + 10 = 110 parameters for the second layer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss=\"categorical_crossentropy\", # Computes the crossentropy loss between the labels and predictions.\n",
    "              optimizer=\"sgd\",\n",
    "              metrics = ['accuracy']) # Calculates how often predictions equals labels."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Compile model with compile() method\n",
    "- Starting with the Sequential model, we can define the layers in a simple way with the add() method.\n",
    "\n",
    "- The next step is to compile the model with the compile() method, with which we can specify some properties through method arguments which are as follows:\n",
    "\n",
    "Loss Function (https://keras.io/api/losses/)\n",
    "- The first argument is the loss function.\n",
    "\n",
    "- We will use it to evaluate the degree of error between calculated outputs and the desired outputs of the training data.\n",
    "\n",
    "Optimizer (https://keras.io/api/optimizers/)\n",
    "- The second argument is the optimizer.\n",
    "\n",
    "- It is the way we have to specify the optimization algorithm that allows the neural network to calculate the weights of the parameters from the input data and the defined loss function.\n",
    "\n",
    "Metrics (https://keras.io/api/metrics/)\n",
    "- The third argument is the metrics.\n",
    "\n",
    "- We must indicate the metric that we will use to monitor the learning process and test of our neural network."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\tor23\\Anaconda3\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:422: The name tf.global_variables is deprecated. Please use tf.compat.v1.global_variables instead.\n",
      "\n",
      "Epoch 1/10\n",
      "28140/28140 [==============================] - 2s 54us/step - loss: 2.2645 - accuracy: 0.1249\n",
      "Epoch 2/10\n",
      "28140/28140 [==============================] - 1s 32us/step - loss: 2.1059 - accuracy: 0.4167\n",
      "Epoch 3/10\n",
      "28140/28140 [==============================] - 1s 31us/step - loss: 1.9760 - accuracy: 0.5596\n",
      "Epoch 4/10\n",
      "28140/28140 [==============================] - 1s 31us/step - loss: 1.8533 - accuracy: 0.6095\n",
      "Epoch 5/10\n",
      "28140/28140 [==============================] - 1s 33us/step - loss: 1.7378 - accuracy: 0.6456\n",
      "Epoch 6/10\n",
      "28140/28140 [==============================] - 1s 39us/step - loss: 1.6299 - accuracy: 0.6719\n",
      "Epoch 7/10\n",
      "28140/28140 [==============================] - 1s 42us/step - loss: 1.5304 - accuracy: 0.6954\n",
      "Epoch 8/10\n",
      "28140/28140 [==============================] - 1s 32us/step - loss: 1.4396 - accuracy: 0.7147\n",
      "Epoch 9/10\n",
      "28140/28140 [==============================] - 1s 34us/step - loss: 1.3572 - accuracy: 0.7314\n",
      "Epoch 10/10\n",
      "28140/28140 [==============================] - 1s 35us/step - loss: 1.2828 - accuracy: 0.7487\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.callbacks.History at 0x21184031278>"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(x_train, y_train, batch_size=100, epochs=10)\n",
    "\n",
    "# The batch_size argument indicates the number of data that we will use for each update of the model parameters.\n",
    "\n",
    "# The epochs argument indicate the number of times we will use all the data in the learning process."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "13860/13860 [==============================] - 1s 54us/step\n"
     ]
    }
   ],
   "source": [
    "test_loss, test_acc = model.evaluate(x_test, y_test)\n",
    "\n",
    "# The model can now be evaluated with the evaluate() method as follows:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test accuracy: 0.7543\n"
     ]
    }
   ],
   "source": [
    "print('Test accuracy:', round(test_acc,4))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Confusion-matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_confusion_matrix(cm, classes,\n",
    "                          normalize=False,\n",
    "                          title='Confusion matrix',\n",
    "                          cmap=plt.cm.Blues):\n",
    "    \"\"\"\n",
    "    This function prints and plots the confusion matrix.\n",
    "    Normalization can be applied by setting `normalize=True`.\n",
    "    \"\"\"\n",
    "    plt.imshow(cm, interpolation='nearest', cmap=cmap)\n",
    "    plt.title(title)\n",
    "    plt.colorbar()\n",
    "    tick_marks = np.arange(len(classes))\n",
    "    plt.xticks(tick_marks, classes, rotation=30)\n",
    "    plt.yticks(tick_marks, classes)\n",
    "\n",
    "    if normalize:\n",
    "        cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
    "\n",
    "    thresh = cm.max() / 2.\n",
    "    for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n",
    "        plt.text(j, i, cm[i, j],\n",
    "                 horizontalalignment=\"center\",\n",
    "                 color=\"white\" if cm[i, j] > thresh else \"black\")\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.ylabel('Actual class')\n",
    "    plt.xlabel('Predicted class')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "from collections import Counter\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import itertools\n",
    "\n",
    "# Predict the values from the validation dataset\n",
    "Y_pred = model.predict(x_test)\n",
    "# Convert predictions classes to one hot vectors \n",
    "Y_pred_classes = np.argmax(Y_pred, axis = 1) \n",
    "# Convert validation observations to one hot vectors\n",
    "Y_true = np.argmax(y_test, axis = 1) \n",
    "# compute the confusion matrix\n",
    "confusion_mtx = confusion_matrix(Y_true, Y_pred_classes) \n",
    "# plot the confusion matrix\n",
    "plot_confusion_matrix(confusion_mtx, classes = range(10))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- In this case, the elements of the diagonal represent the number of points in which the label predicted by the model coincides with the actual value of the label, while the other values indicate the cases in which the model has classified incorrectly.\n",
    "\n",
    "- Therefore, the higher the values of the diagonal, the better the prediction will be.\n",
    "\n",
    "- If we calculate the sum of the values of the diagonal divided by the total values of the matrix, we get the same accuracy that the evaluate() method has returned."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = model.predict(x_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- The predict() method return a vector with the predictions for the whole dataset elements.\n",
    "- We know which class gives the most probability of belonging by means of the argmax function of Numpy, which returns the index of the position that contains the highest value of the vector."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.argmax(predictions[11])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.1357197  0.06231341 0.10343719 0.33734652 0.03020793 0.13135026\n",
      " 0.0646946  0.01855368 0.08367935 0.03269728]\n"
     ]
    }
   ],
   "source": [
    "print(predictions[11])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- We see that the highest value in the vector is in the position 3.\n",
    "\n",
    "- We can also verify that the result of the prediction is a vector whose sum of all its components is equal to 1, as expected."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.99999994"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.sum(predictions[11])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Try some different combination"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1) Activation Functions (sigmoid, tanh, relu)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "activations = ['sigmoid', 'tanh', 'relu']\n",
    "\n",
    "for activation in activations:\n",
    "\n",
    "    model = Sequential()\n",
    "    model.add(Dense(10, activation=activation, input_shape=(784,)))\n",
    "    model.add(Dense(10, activation='softmax'))\n",
    "\n",
    "    model.compile(loss=\"categorical_crossentropy\", # Computes the crossentropy loss between the labels and predictions.\n",
    "                  optimizer=\"adam\",\n",
    "                  metrics = ['accuracy']) # Calculates how often predictions equals labels.\n",
    "\n",
    "    model.fit(x_train, y_train, batch_size=100, epochs=10, verbose = 0)\n",
    "\n",
    "    train_loss, train_acc = model.evaluate(x_train, y_train)\n",
    "    print(activation, 'Train accuracy:', round(train_acc,4))\n",
    "\n",
    "    test_loss, test_acc = model.evaluate(x_test, y_test)\n",
    "    print(activation, 'Test accuracy:', round(test_acc,4))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- We can see that 'sigmoid' is low accuracy so we use generally sigmoid function in dropout when there is one class, \n",
    "- tanh and relu scores are very close"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2) Compare Node"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "nodes = [10,50,100]\n",
    "\n",
    "for node in nodes:\n",
    "\n",
    "    model = Sequential()\n",
    "    model.add(Dense(node, activation='relu', input_shape=(784,)))\n",
    "    model.add(Dense(10, activation='softmax'))\n",
    "\n",
    "    model.compile(loss=\"categorical_crossentropy\", # Computes the crossentropy loss between the labels and predictions.\n",
    "                  optimizer=\"adam\",\n",
    "                  metrics = ['accuracy']) # Calculates how often predictions equals labels.\n",
    "\n",
    "    model.fit(x_train, y_train, batch_size=100, epochs=10, verbose = 0)\n",
    "\n",
    "    train_loss, train_acc = model.evaluate(x_train, y_train)\n",
    "    print('node number:', node, 'Train accuracy:', round(train_acc,4))\n",
    "\n",
    "    test_loss, test_acc = model.evaluate(x_test, y_test)\n",
    "    print('node number:', node, 'Test accuracy:', round(test_acc,4))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- When increase node number, accuracy is increasing but there is a limit, we have to find it"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3) Compare Layer Number"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(Dense(50, activation='relu', input_shape=(784,)))\n",
    "model.add(Dense(10, activation='softmax'))\n",
    "model.compile(loss=\"categorical_crossentropy\", # Computes the crossentropy loss between the labels and predictions.\n",
    "              optimizer=\"adam\",\n",
    "              metrics = ['accuracy']) # Calculates how often predictions equals labels.\n",
    "\n",
    "model.fit(x_train, y_train, batch_size=100, epochs=10, verbose = 0)\n",
    "\n",
    "train_loss, train_acc = model.evaluate(x_train, y_train)\n",
    "print('One hidden layer Train accuracy:', round(train_acc,4))\n",
    "\n",
    "test_loss, test_acc = model.evaluate(x_test, y_test)\n",
    "print('One hidden layer Test accuracy:', round(test_acc,4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(Dense(50, activation='relu', input_shape=(784,)))\n",
    "model.add(Dense(50, activation='relu'))\n",
    "model.add(Dense(10, activation='softmax'))\n",
    "\n",
    "model.compile(loss=\"categorical_crossentropy\", # Computes the crossentropy loss between the labels and predictions.\n",
    "              optimizer=\"adam\",\n",
    "              metrics = ['accuracy']) # Calculates how often predictions equals labels.\n",
    "\n",
    "model.fit(x_train, y_train, batch_size=100, epochs=10, verbose = 0)\n",
    "\n",
    "train_loss, train_acc = model.evaluate(x_train, y_train)\n",
    "print('Two hidden layer Train accuracy:', round(train_acc,4))\n",
    "\n",
    "test_loss, test_acc = model.evaluate(x_test, y_test)\n",
    "print('Two hidden layer Test accuracy:', round(test_acc,4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(Dense(50, activation='relu', input_shape=(784,)))\n",
    "model.add(Dense(50, activation='relu'))\n",
    "model.add(Dense(50, activation='relu'))\n",
    "model.add(Dense(10, activation='softmax'))\n",
    "\n",
    "model.compile(loss=\"categorical_crossentropy\", # Computes the crossentropy loss between the labels and predictions.\n",
    "              optimizer=\"adam\",\n",
    "              metrics = ['accuracy']) # Calculates how often predictions equals labels.\n",
    "\n",
    "model.fit(x_train, y_train, batch_size=100, epochs=10, verbose = 0)\n",
    "\n",
    "train_loss, train_acc = model.evaluate(x_train, y_train)\n",
    "print('Three hidden layer Train accuracy:', round(train_acc,4))\n",
    "\n",
    "test_loss, test_acc = model.evaluate(x_test, y_test)\n",
    "print('Three hidden layer Test accuracy:', round(test_acc,4))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- The larger models (with more hidden units) are able to fit the training set better, until eventually the largest models overfit the data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4) Optimizer (SGD, RMSprop, Adam)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In Stochastic Gradient Descent, you use only 1 training example before updating the gradients. When the training set is large, SGD can be faster. But the parameters will \"oscillate\" toward the minimum rather than converge smoothly. \n",
    "\n",
    "The difference between gradient descent, mini-batch gradient descent and stochastic gradient descent is the number of examples you use to perform one update step.\n",
    "\n",
    "Because mini-batch gradient descent makes a parameter update after seeing just a subset of examples, the direction of the update has some variance, and so the path taken by mini-batch gradient descent will \"oscillate\" toward convergence. Using momentum can reduce these oscillations.\n",
    "\n",
    "Adam is one of the most effective optimization algorithms for training neural networks. It combines ideas from RMSProp and Momentum.\n",
    "\n",
    "Momentum usually helps, but given the small learning rate and the simplistic dataset, its impact is almost negligeable. Also, the huge oscillations you see in the cost come from the fact that some minibatches are more difficult thans others for the optimization algorithm.\n",
    "\n",
    "Adam on the other hand, clearly outperforms mini-batch gradient descent and Momentum. If you run the model for more epochs on this simple dataset, all three methods will lead to very good results. However, you've seen that Adam converges a lot faster.\n",
    "\n",
    "Some advantages of Adam include:\n",
    "\n",
    "Relatively low memory requirements (though higher than gradient descent and gradient descent with momentum)\n",
    "Usually works well even with little tuning of hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizers = ['SGD', 'RMSprop', 'Adam']\n",
    "\n",
    "for optimizer in optimizers:\n",
    "\n",
    "    model = Sequential()\n",
    "    model.add(Dense(10, activation='relu', input_shape=(784,)))\n",
    "    model.add(Dense(10, activation='softmax'))\n",
    "\n",
    "    model.compile(loss=\"categorical_crossentropy\", # Computes the crossentropy loss between the labels and predictions.\n",
    "                  optimizer=optimizer,\n",
    "                  metrics = ['accuracy']) # Calculates how often predictions equals labels.\n",
    "\n",
    "    model.fit(x_train, y_train, batch_size=100, epochs=10, verbose = 0)\n",
    "\n",
    "    train_loss, train_acc = model.evaluate(x_train, y_train)\n",
    "    print(optimizer, 'Train accuracy:', round(train_acc,4))\n",
    "\n",
    "    test_loss, test_acc = model.evaluate(x_test, y_test)\n",
    "    print(optimizer, 'Test accuracy:', round(test_acc,4))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- SGD is very low but RMSprop and ADAM are better"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5) Batch Size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_sizes = [16, 32, 64, 128, 256]\n",
    "\n",
    "for batch_size in batch_sizes:\n",
    "\n",
    "    model = Sequential()\n",
    "    model.add(Dense(10, activation='relu', input_shape=(784,)))\n",
    "    model.add(Dense(10, activation='softmax'))\n",
    "\n",
    "    model.compile(loss=\"categorical_crossentropy\", # Computes the crossentropy loss between the labels and predictions.\n",
    "                  optimizer='Adam',\n",
    "                  metrics = ['accuracy']) # Calculates how often predictions equals labels.\n",
    "\n",
    "    model.fit(x_train, y_train, batch_size=batch_size, epochs=10, verbose = 0)\n",
    "\n",
    "    train_loss, train_acc = model.evaluate(x_train, y_train)\n",
    "    print('batch_size:', batch_size, 'Train accuracy:', round(train_acc,4))\n",
    "\n",
    "    test_loss, test_acc = model.evaluate(x_test, y_test)\n",
    "    print('batch_size:', batch_size, 'Test accuracy:', round(test_acc,4))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6) Epochs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs = [10, 50, 100]\n",
    "\n",
    "for epochs in epochs:\n",
    "\n",
    "    model = Sequential()\n",
    "    model.add(Dense(10, activation='relu', input_shape=(784,)))\n",
    "    model.add(Dense(10, activation='softmax'))\n",
    "\n",
    "    model.compile(loss=\"categorical_crossentropy\", # Computes the crossentropy loss between the labels and predictions.\n",
    "                  optimizer='Adam',\n",
    "                  metrics = ['accuracy']) # Calculates how often predictions equals labels.\n",
    "\n",
    "    model.fit(x_train, y_train, batch_size=100, epochs=epochs, verbose = 0)\n",
    "\n",
    "    train_loss, train_acc = model.evaluate(x_train, y_train)\n",
    "    print('epochs:', epochs, 'Train accuracy:', round(train_acc,4))\n",
    "\n",
    "    test_loss, test_acc = model.evaluate(x_test, y_test)\n",
    "    print('epochs:', epochs, 'Test accuracy:', round(test_acc,4))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 7) Learning Rate"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In order for Gradient Descent to work you must choose the learning rate wisely. The learning rate $\\alpha$ determines how rapidly we update the parameters. If the learning rate is too large we may \"overshoot\" the optimal value. Similarly, if it is too small we will need too many iterations to converge to the best values. That's why it is crucial to use a well-tuned learning rate.\n",
    "\n",
    "Let's compare the learning curve of our model with several choices of learning rates. Run the cell below. This should take about 1 minute. Feel free also to try different values than the three we have initialized the learning_rates variable to contain, and see what happens."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Default value is 0.001\n",
    "\n",
    "tf.keras.optimizers.Adam(\n",
    "    learning_rate=0.001,\n",
    "    beta_1=0.9,\n",
    "    beta_2=0.999,\n",
    "    epsilon=1e-07,\n",
    "    amsgrad=False,\n",
    "    name=\"Adam\",\n",
    "    **kwargs\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.optimizers import adam\n",
    "\n",
    "learning_rates = [0.01, 0.001, 0.0001]\n",
    "\n",
    "for learning_rate in learning_rates:\n",
    "\n",
    "    model = Sequential()\n",
    "    model.add(Dense(10, activation='relu', input_shape=(784,)))\n",
    "    model.add(Dense(10, activation='softmax'))\n",
    "\n",
    "    #opt = keras.optimizers.Adam(learning_rate=learning_rate)\n",
    "    \n",
    "    model.compile(loss=\"categorical_crossentropy\", # Computes the crossentropy loss between the labels and predictions.\n",
    "                  optimizer=adam(lr = learning_rate),\n",
    "                  metrics = ['accuracy']) # Calculates how often predictions equals labels.\n",
    "\n",
    "    model.fit(x_train, y_train, batch_size=100, epochs=epochs, verbose = 0)\n",
    "\n",
    "    train_loss, train_acc = model.evaluate(x_train, y_train)\n",
    "    print('learning_rate:', learning_rate, 'Train accuracy:', round(train_acc,4))\n",
    "\n",
    "    test_loss, test_acc = model.evaluate(x_test, y_test)\n",
    "    print('learning_rate:', learning_rate, 'Test accuracy:', round(test_acc,4))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Different learning rates give different costs and thus different predictions results.\n",
    "- If the learning rate is too large (0.01), the cost may oscillate up and down. It may even diverge (though in this example, using 0.01 still eventually ends up at a good value for the cost).\n",
    "- A lower cost doesn't mean a better model. You have to check if there is possibly overfitting. It happens when the training accuracy is a lot higher than the test accuracy.\n",
    "- In deep learning, we usually recommend that you:\n",
    "    -Choose the learning rate that better minimizes the cost function.\n",
    "    -If your model overfits, use other techniques to reduce overfitting."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 8) Usage of initializers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Training your neural network requires specifying an initial value of the weights. A well chosen initialization method will help learning.\n",
    "- A well chosen initialization can: Speed up the convergence of gradient descent. Increase the odds of gradient descent converging to a lower training (and generalization) error\n",
    "- Zeros initialization\n",
    "- Random initialization\n",
    "- He initialization\n",
    "\n",
    "- Initializers define the way to set the initial random weights of Keras layers."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 9) Regularization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Deep Learning models have so much flexibility and capacity that overfitting can be a serious problem, if the training dataset is not big enough. Sure it does well on the training set, but the learned network doesn't generalize to new examples that it has never seen!\n",
    "\n",
    "in regularization mode -- by setting the lambd input to a non-zero value. We use \"lambd\" instead of \"lambda\" because \"lambda\" is a reserved keyword in Python.\n",
    "in dropout mode -- by setting the keep_prob to a value less than one\n",
    "\n",
    "Finally, dropout is a widely used regularization technique that is specific to deep learning. It randomly shuts down some neurons in each iteration.\n",
    "\n",
    "When you shut some neurons down, you actually modify your model. The idea behind drop-out is that at each iteration, you train a different model that uses only a subset of your neurons. With dropout, your neurons thus become less sensitive to the activation of one other specific neuron, because that other neuron might be shut down at any time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from tensorflow.keras import regularizers\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Dense(20, activation='relu', input_shape=(784,)))\n",
    "layers.Dropout(0.5),\n",
    "model.add(Dense(20, activation='relu', ))\n",
    "layers.Dropout(0.5),\n",
    "model.add(Dense(20, activation='relu', ))\n",
    "layers.Dropout(0.5),\n",
    "model.add(Dense(20, activation='relu', ))\n",
    "layers.Dropout(0.5),\n",
    "model.add(Dense(10, activation='softmax', activity_regularizer=tf.keras.regularizers.l2(0.5)))\n",
    "\n",
    "model.compile(loss=\"categorical_crossentropy\", # Computes the crossentropy loss between the labels and predictions.\n",
    "              optimizer=adam(lr = 0.001),\n",
    "              metrics = ['accuracy']) # Calculates how often predictions equals labels.\n",
    "\n",
    "model.fit(x_train, y_train, batch_size=32, epochs=30, verbose = 2)\n",
    "\n",
    "train_loss, train_acc = model.evaluate(x_train, y_train)\n",
    "print('Train accuracy:', round(train_acc,4), 'Train loss:', round(train_loss,4))\n",
    "\n",
    "test_loss, test_acc = model.evaluate(x_test, y_test)\n",
    "print('Test accuracy:', round(test_acc,4), 'Test loss:', round(test_loss,4))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# FINAL MODEL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "\n",
    "model.add(Dense(250, activation='relu', input_shape=(784,)))\n",
    "\n",
    "model.add(Dense(250, activation='relu'))\n",
    "\n",
    "model.add(Dense(250, activation='relu'))\n",
    "\n",
    "model.add(Dense(10, activation='softmax'))\n",
    "\n",
    "model.compile(loss=\"categorical_crossentropy\", \n",
    "              optimizer='Adam',\n",
    "              metrics = ['accuracy']) \n",
    "\n",
    "model.fit(x_train, y_train, batch_size=32, epochs=20, verbose = 2)\n",
    "\n",
    "train_loss, train_acc = model.evaluate(x_train, y_train)\n",
    "print('Train accuracy:', round(train_acc,4), 'Train loss:', round(train_loss,4))\n",
    "\n",
    "test_loss, test_acc = model.evaluate(x_test, y_test)\n",
    "print('Test accuracy:', round(test_acc,4), 'Test loss:', round(test_loss,4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predict () yöntemi, tüm veri kümesi öğelerinin tahminlerini içeren bir vektör döndürür.\n",
    "test_result = model.predict(test)\n",
    "\n",
    "# Sonucları bir csv dosyasına kaydetmek\n",
    "\n",
    "# Convert one-hot vector to number\n",
    "results = np.argmax(test_result,axis = 1) # bu bize prediction vektöründeki en yüksek olasılığa göre ilgili y değerini verir mesela 2 ya da 3\n",
    "\n",
    "results = pd.Series(results,name=\"Label\")\n",
    "\n",
    "\n",
    "submission = pd.concat([pd.Series(range(1,28001),name = \"ImageId\"),results],axis = 1)\n",
    "\n",
    "submission.to_csv(\"test_submission_best.csv\",index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot confusion matrix \n",
    "# Note: This code snippet for confusion-matrix is taken directly from the SKLEARN website.\n",
    "def plot_confusion_matrix(cm, classes,\n",
    "                          normalize=False,\n",
    "                          title='Confusion matrix',\n",
    "                          cmap=plt.cm.Blues):\n",
    "    \"\"\"\n",
    "    This function prints and plots the confusion matrix.\n",
    "    Normalization can be applied by setting `normalize=True`.\n",
    "    \"\"\"\n",
    "    plt.imshow(cm, interpolation='nearest', cmap=cmap)\n",
    "    plt.title(title)\n",
    "    plt.colorbar()\n",
    "    tick_marks = np.arange(len(classes))\n",
    "    plt.xticks(tick_marks, classes, rotation=30)\n",
    "    plt.yticks(tick_marks, classes)\n",
    "\n",
    "    if normalize:\n",
    "        cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
    "\n",
    "    thresh = cm.max() / 2.\n",
    "    for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n",
    "        plt.text(j, i, cm[i, j],\n",
    "                 horizontalalignment=\"center\",\n",
    "                 color=\"white\" if cm[i, j] > thresh else \"black\")\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.ylabel('Actual class')\n",
    "    plt.xlabel('Predicted class')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import itertools\n",
    "\n",
    "# Predict the values from the validation dataset\n",
    "Y_pred = model.predict(x_test)\n",
    "# Convert predictions classes to one hot vectors \n",
    "Y_pred_classes = np.argmax(Y_pred, axis = 1) \n",
    "# Convert validation observations to one hot vectors\n",
    "Y_true = np.argmax(y_test, axis = 1) \n",
    "# compute the confusion matrix\n",
    "confusion_mtx = confusion_matrix(Y_true, Y_pred_classes) \n",
    "# plot the confusion matrix\n",
    "plot_confusion_matrix(confusion_mtx, classes = range(10))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
